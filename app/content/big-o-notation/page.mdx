---
title: Why use Big-O Notation?
description: What is Big-O Notation and how to calculate it?
thumbnail: https://i.ytimg.com/vi/Q_1M2JaijjQ/maxresdefault.jpg
date: 2023-12-27T10:54:47.000Z
categories:
  - algorithm
  - science
  - computer-science
authors:
  - gelzinn
---

## What is Big-O Notation?

Big-O notation is a way of describing the performance of an algorithm. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows.

It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows.

## How to calculate Big-O Notation?

Big-O notation is a way of describing the performance of an algorithm. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows. It is a way of describing how the runtime of an algorithm scales as the input grows.
